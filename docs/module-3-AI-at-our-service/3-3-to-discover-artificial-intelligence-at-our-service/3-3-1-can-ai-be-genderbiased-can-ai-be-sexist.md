---
title: Can AI be Gender-biased?
description:
---

### Can AI be Gender-biased?

_Translated text from the french IAI Mooc._

![Illustration gender-biased](../Images/ondira-levrres-intelligence-artificielle-femmes.jpg)

Photo : CBC/Radio-Canada -iStock - Editing: Amarilys Proulx

An artificial intelligence does not think. So can it be racist, sexist or homophobic? It is possible for it to reproduce discriminatory mechanisms, if the mechanism has been trained by biased data. Human beings havecognitive biases in their reasoning.

**Cognitive biases** are the set of psychological, moral, social, cultural... factors that influence, without our realizing it, our thinking mechanisms. These cognitive biases have an impact on logical thinking, as they influence our ways of thinking and lead us to make decisions guided by factors that are not rational. They can then be the cause of discriminatory decisions.

But it is we who provide data to the algorithms. If there are biases in the data provided, this will be reflected in the results. For example, the company Amazon has standard recruitment needs, and to make it easier to manage them, it decided to use an artificial intelligence capable of sorting CVs. In order for this AI to learn how to sort profiles, Amazon provided all the recruitment data it had recorded between 2004 and 2014. However, after a year, Amazon realised that the AI was systematically rejecting female profiles for technical and IT positions. The artificial intelligence, had simply determined by analysing the data it had been provided, that the recruitment for these positions over the last ten years was largely male<sup>1</sup>. Amazon stopped this artificial intelligence because the results obtained had gender biases. But it's not just biases in the data, there are also biases in the way the algorithms themselves are implemented.

Technologies are therefore not neutral; they indirectly reflect the ways in which their designers and our societies operate. Even factors such as language can have an influence on them. In France, the composition of the language favours gendered learning more than in other countries. As names are predominantly masculine, an algorithm knows more masculine names than feminine ones. Thus, translation sites, such as Google translation, tend to give a masculine translation of names that are gender-neutral in another language<sup>2</sup>.

Artificial intelligence can reinforce inequities as well as combat them. Faced with these ethical and technical challenges, several modes of action are envisaged. For example, guaranteeing more gender diversity in computer sciences, so that men are no longer over-represented. Or to overcome cognitive biases by teaching the algorithm to recognise them. This second option requires designers to consider cognitive biases upstream, even though they are not always aware of them. The best solution is to ensure diversity in the learning data, as data can be easier to change than mindsets.<sup>3</sup>

* * *

<sup>1</sup> _[Amazon a dû se débarrasser d’une intelligence artificielle sexiste”,](http://www.slate.fr/story/168413/amazon-abandonne-intelligence-artificielle-sexiste) Slatefr,10 octobre 2018. ; [Amazon met fin à une intelligence artificielle sexiste”](https://www.franceinter.fr/emissions/c-est-deja-demain/c-est-deja-demain-12-octobre-2018) par Hélène Chevallier, France Inter, emission c'est déjà demain, vendredi 12 octobre 2018 ; [Amazon a du débrancher un logiciel de recrutement qui s’est révélé sexiste”](https://www.europe1.fr/emissions/axel-de-tarle-vous-parle-economie/amazon-a-du-debrancher-une-logiciel-de-recrutement-qui-sest-revele-sexiste-37768493), La matinale d'Europe 1, le 6h - 9h, l'édito économique d'Axel de Tarlé, le 12 octobre 2018._  
<sup>2</sup> _[Quand l’Intelligence Artificielle rencontre les Sciences du Langage”](https://chut.media/portraits/intelligence-artificielle-sciences-du-langage/) par Aurore Bisicchia, Chut!, janvier 2005._  
<sup>3</sup> _[“L’IA est–elle sexiste, elle aussi ?”](https://www.lemonde.fr/blog/binaire/2018/03/08/lia-est-elle-sexiste-elle-aussi/) par Anne-Marie Kermarrec, Blog Binaire, Le Monde, 08 mars 2018._  
_["Les biais sexistes de l'IA peuvent être corrigés, selon les chercheuses Aude Bernheim et Flora Vincent"](https://www.usinenouvelle.com/editorial/les-biais-sexistes-de-l-ia-peuvent-etre-corriges-selon-les-chercheuses-aude-bernheim-et-flora-vincent.N815345), L'Usine Nouvelle, propos recueillis par Marion Garreau, 08/03/2019._  
_["Le secteur de l’intelligence artificielle est aussi masculin qu’un bar des sports le soir d’un match de Ligue 1”](https://www.lopinion.fr/edition/politique/secteur-l-intelligence-artificielle-est-aussi-masculin-qu-bar-sports-180114), Interview d'Aude Bernheim et Flora Vincent par Irène Inchauspé, L’opinion, 08 Mars 2019._
