---
title: What types of AI?
description: Describe main existing AI applications, what are their potential or existing uses in Education
---

*to be modified* 
Many AI definitions and classification can be found in the litterature. Although AI has entered the common language, there is no really shared definition.  
One of the classification distinguishes between weak AI and strong AI. An other one refers to symbolic or numerical approaches to artificial intelligence.Â  Let's see what do they refer to.

_Translated text from the french IAI Mooc._

Weak or strong AI?
------------------

The expression "artificial intelligence", created in the 1950s, refers to the field of research that studies the mechanisms of intelligence by modelling them with algorithms and experimenting with machines. These mechanisms include, for example, the ability to automatically find solutions to problems, which may involve planning, prediction, control, memory or learning. By extension, the term "artificial intelligence" is often used to refer to algorithms that simulate or share some of the intelligence capabilities of living beings.

*   **Weak artificial intelligence**  
    This is the artificial intelligence we know today: it is an algorithm that "learns", by adapting its parameters to learning data, and is not endowed with mental and cognitive capacities, but is capable of performing a specific task much more efficiently, sometimes more so than a human being.
*   **Strong artificial intelligence**  
    An artificial intelligence that would be capable of copying human aptitudes (learning, understanding, apprehending, reasoning, making decisions, having a conscience, emotions, etc.). To date, strong artificial intelligence does not exist, it is a belief.

Symbolic or numerical approach?
-------------------------------

Let's imagine that we want to program a kitchen robot to make a pot au feu, we can:

*   have a **symbolic approach**, i.e. based on logic and a priori knowledge.  
    If you are a specialist in this recipe, you can explicitly give a series of rules and principles for making a pot au feu: this will be very good if you are a great cook and can even propose very high level techniques, with complicated reasoning.
*   have a **numerical approach**, i.e. based on data and learning.  
    Without knowing too well how it is done, but by observing many other people who make pots on fire, we will be able to draw general rules from a statistical and therefore numerical analysis of their methods and propose solutions. This will certainly be less explicit than with knowledge already acquired, but it will be more flexible and adaptive because it will be based on the diversity of observations. It might even be possible to find things that no one has experienced before (for example, that some people put the meat in before or after heating the water).

Each of these two approaches makes it possible to make a machine perform functions that would have been considered intelligent if done by a human: you are an expert and you formalise and specify your knowledge or you observe and imitate without having any a priori knowledge, trying to make this knowledge emerge by analysis and comparison of similar cases, by learning. This corresponds to two different faculties of the brain: I know that (explicit memory) or I know how to do (or rather I learn to do by experience, implicit memory).  

Historically, the symbolic approach is older, corresponding to expert systems, and more recently to the so-called semantic web. By formalising our knowledge in the form of ontologies, its great advantage is to be able to introduce specific knowledge a priori, before applying rules to automate a certain amount of reasoning. It also has the merit of being able to be used even with little data. It is based on formalisations of logic. The numerical approach corresponds, for example, to what is known as artificial neural networks, deep learning when there are several layers of such computing units. It has become effective more recently, and it is this approach that allows us to automatically transcribe texts that we dictate, or to recognise objects in images. It requires a lot of data and is based on statistical approaches. It is a current research topic to see how to combine the two approaches.  


A [Glossary about AI is published by the Council of Europe](https://www.coe.int/en/web/artificial-intelligence/glossary). Some more AI related terms are defined.
